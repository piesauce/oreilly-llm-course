{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/piesauce/oreilly-llm-course/blob/main/MCP_Server_oreilly.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "de583010",
      "metadata": {
        "id": "de583010"
      },
      "source": [
        "# MCP Server 101 (Simple): Weather Tools (Free API, No Key)\n",
        "\n",
        "This notebook builds a **tiny MCP server** that exposes **2 tools** backed by the free **Open‑Meteo** endpoints:\n",
        "\n",
        "- `search_locations(query)` → finds a city and returns lat/lon  \n",
        "- `get_current_weather(latitude, longitude)` → current temperature + wind + weather code  \n",
        "- `umbrella_advice(query)` → a friendly answer using precipitation probability (optional but fun)\n",
        "\n",
        "✅ **No API keys.**  \n",
        "✅ Runs in Colab.  \n",
        "✅ Includes a minimal **stdio client test** (so you can demo MCP without any desktop app).\n",
        "\n",
        "> **Important:** MCP stdio servers must not print to stdout. We use logging to stderr.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip -q install -U \"mcp[cli]\" httpx nest_asyncio\n",
        "\n",
        "import mcp\n",
        "print(\"mcp version:\", getattr(mcp, \"__version__\", \"unknown\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fro58XEq111w",
        "outputId": "a27dab8d-e8a5-4ba1-cee3-2c844afa9d49"
      },
      "id": "fro58XEq111w",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mcp version: unknown\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile weather_mcp_server.py\n",
        "from typing import Any, Dict\n",
        "import httpx\n",
        "from mcp.server.fastmcp import FastMCP\n",
        "\n",
        "mcp = FastMCP(\"weather-mcp-simple\")\n",
        "\n",
        "GEOCODE_URL = \"https://geocoding-api.open-meteo.com/v1/search\"\n",
        "FORECAST_URL = \"https://api.open-meteo.com/v1/forecast\"\n",
        "\n",
        "\n",
        "@mcp.tool()\n",
        "async def search_locations(query: str, count: int = 5) -> Dict[str, Any]:\n",
        "    \"\"\"Find a place (city) and return up to `count` matches with lat/lon.\"\"\"\n",
        "    params = {\"name\": query, \"count\": count, \"language\": \"en\", \"format\": \"json\"}\n",
        "    async with httpx.AsyncClient(timeout=20) as client:\n",
        "        r = await client.get(GEOCODE_URL, params=params)\n",
        "        r.raise_for_status()\n",
        "        data = r.json()\n",
        "\n",
        "    results = data.get(\"results\") or []\n",
        "    return {\n",
        "        \"query\": query,\n",
        "        \"results\": [\n",
        "            {\n",
        "                \"name\": x.get(\"name\"),\n",
        "                \"country\": x.get(\"country\"),\n",
        "                \"admin1\": x.get(\"admin1\"),\n",
        "                \"latitude\": x.get(\"latitude\"),\n",
        "                \"longitude\": x.get(\"longitude\"),\n",
        "                \"timezone\": x.get(\"timezone\"),\n",
        "            }\n",
        "            for x in results\n",
        "        ],\n",
        "    }\n",
        "\n",
        "\n",
        "@mcp.tool()\n",
        "async def get_current_weather(latitude: float, longitude: float, timezone: str = \"auto\") -> Dict[str, Any]:\n",
        "    \"\"\"Current weather at a lat/lon (temp, wind, weather_code).\"\"\"\n",
        "    params = {\n",
        "        \"latitude\": latitude,\n",
        "        \"longitude\": longitude,\n",
        "        \"timezone\": timezone,\n",
        "        \"current\": \"temperature_2m,wind_speed_10m,wind_direction_10m,weather_code\",\n",
        "    }\n",
        "    async with httpx.AsyncClient(timeout=20) as client:\n",
        "        r = await client.get(FORECAST_URL, params=params)\n",
        "        r.raise_for_status()\n",
        "        data = r.json()\n",
        "\n",
        "    current = data.get(\"current\") or {}\n",
        "    return {\n",
        "        \"timezone\": data.get(\"timezone\"),\n",
        "        \"latitude\": latitude,\n",
        "        \"longitude\": longitude,\n",
        "        \"current\": {\n",
        "            \"time\": current.get(\"time\"),\n",
        "            \"temperature_2m\": current.get(\"temperature_2m\"),\n",
        "            \"wind_speed_10m\": current.get(\"wind_speed_10m\"),\n",
        "            \"wind_direction_10m\": current.get(\"wind_direction_10m\"),\n",
        "            \"weather_code\": current.get(\"weather_code\"),\n",
        "        },\n",
        "    }\n",
        "\n",
        "\n",
        "@mcp.tool()\n",
        "async def umbrella_advice(city: str) -> Dict[str, Any]:\n",
        "    \"\"\"Umbrella advice for the next 12 hours, based on precip probability.\"\"\"\n",
        "    geo = await search_locations(city, count=1)\n",
        "    if not geo[\"results\"]:\n",
        "        return {\"city\": city, \"advice\": \"Couldn't find that place. Try a bigger nearby city.\"}\n",
        "\n",
        "    loc = geo[\"results\"][0]\n",
        "    lat, lon = loc[\"latitude\"], loc[\"longitude\"]\n",
        "\n",
        "    params = {\n",
        "        \"latitude\": lat,\n",
        "        \"longitude\": lon,\n",
        "        \"timezone\": \"auto\",\n",
        "        \"hourly\": \"precipitation_probability\",\n",
        "        \"forecast_hours\": 12,\n",
        "    }\n",
        "    async with httpx.AsyncClient(timeout=20) as client:\n",
        "        r = await client.get(FORECAST_URL, params=params)\n",
        "        r.raise_for_status()\n",
        "        data = r.json()\n",
        "\n",
        "    hourly = data.get(\"hourly\") or {}\n",
        "    probs = hourly.get(\"precipitation_probability\") or []\n",
        "    times = hourly.get(\"time\") or []\n",
        "\n",
        "    if not probs:\n",
        "        return {\"city\": city, \"location\": loc, \"advice\": \"No precipitation probability data available.\"}\n",
        "\n",
        "    peak = max(probs)\n",
        "    peak_i = probs.index(peak)\n",
        "    peak_time = times[peak_i] if peak_i < len(times) else None\n",
        "\n",
        "    if peak >= 60:\n",
        "        advice = f\"Bring an umbrella. Peak precip probability ~{peak}% around {peak_time}.\"\n",
        "    elif peak >= 30:\n",
        "        advice = f\"Maybe bring an umbrella. Peak precip probability ~{peak}% around {peak_time}.\"\n",
        "    else:\n",
        "        advice = f\"Probably no umbrella needed. Peak precip probability ~{peak}%.\"\n",
        "\n",
        "    return {\"city\": city, \"location\": loc, \"peak_probability\": peak, \"peak_time\": peak_time, \"advice\": advice}\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Default is stdio; explicit is fine too: mcp.run(transport=\"stdio\")\n",
        "    mcp.run()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LtqOxhnX17Q5",
        "outputId": "b4dff922-f1d4-486c-c58b-855ae8d6ab30"
      },
      "id": "LtqOxhnX17Q5",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing weather_mcp_server.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import nest_asyncio\n",
        "import sys\n",
        "from pathlib import Path\n",
        "\n",
        "nest_asyncio.apply()\n",
        "\n",
        "from mcp import ClientSession, StdioServerParameters, types\n",
        "from mcp.client.stdio import stdio_client\n",
        "\n",
        "server_params = StdioServerParameters(\n",
        "    command=sys.executable,\n",
        "    args=[\"weather_mcp_server.py\"],\n",
        "    env=None,\n",
        ")\n",
        "\n",
        "def unpack_call_result(result):\n",
        "    \"\"\"\n",
        "    Robust parsing across MCP versions:\n",
        "    - Prefer structuredContent if present\n",
        "    - Else try to parse first TextContent as JSON\n",
        "    - Else fall back to raw text\n",
        "    \"\"\"\n",
        "    if hasattr(result, \"structuredContent\") and result.structuredContent:\n",
        "        return result.structuredContent\n",
        "\n",
        "    if getattr(result, \"content\", None):\n",
        "        for c in result.content:\n",
        "            if isinstance(c, types.TextContent):\n",
        "                txt = c.text\n",
        "                try:\n",
        "                    return json.loads(txt)\n",
        "                except Exception:\n",
        "                    return {\"text\": txt}\n",
        "\n",
        "    return {\"text\": str(result)}\n",
        "\n",
        "async def run_test():\n",
        "    err_path = Path(\"/tmp/mcp_server_stderr.log\")\n",
        "    with err_path.open(\"w\") as errlog:\n",
        "        async with stdio_client(server_params, errlog=errlog) as (read, write):\n",
        "            async with ClientSession(read, write) as session:\n",
        "                await session.initialize()\n",
        "\n",
        "                tools = await session.list_tools()\n",
        "                print(\"TOOLS:\", [t.name for t in tools.tools])\n",
        "\n",
        "                locs = await session.call_tool(\"search_locations\", {\"query\": \"Toronto\", \"count\": 3})\n",
        "                locs_data = unpack_call_result(locs)\n",
        "                print(\"\\nLOCATIONS:\")\n",
        "                print(json.dumps(locs_data, indent=2)[:1200])\n",
        "                payload = locs_data.get(\"result\", locs_data)   # <-- unwrap if needed\n",
        "                first = (payload.get(\"results\") or [None])[0]\n",
        "\n",
        "                if not first:\n",
        "                    print(\"No results; stopping.\")\n",
        "                    return\n",
        "\n",
        "                wx = await session.call_tool(\n",
        "                    \"get_current_weather\",\n",
        "                    {\"latitude\": first[\"latitude\"], \"longitude\": first[\"longitude\"], \"timezone\": first.get(\"timezone\") or \"auto\"},\n",
        "                )\n",
        "                wx_data = unpack_call_result(wx)\n",
        "                print(\"\\nCURRENT WEATHER:\")\n",
        "                print(json.dumps(wx_data, indent=2))\n",
        "\n",
        "                umb = await session.call_tool(\"umbrella_advice\", {\"city\": \"Toronto\"})\n",
        "                umb_data = unpack_call_result(umb)\n",
        "                print(\"\\nUMBRELLA ADVICE:\")\n",
        "                print(json.dumps(umb_data, indent=2))\n",
        "\n",
        "try:\n",
        "    await run_test()\n",
        "except BaseExceptionGroup as eg:\n",
        "    print(\"\\n--- MCP TEST FAILED (ExceptionGroup) ---\")\n",
        "    for i, e in enumerate(eg.exceptions, 1):\n",
        "        print(f\"[{i}] {type(e).__name__}: {e}\")\n",
        "    p = Path(\"/tmp/mcp_server_stderr.log\")\n",
        "    print(\"\\n--- server stderr tail ---\")\n",
        "    print(p.read_text(errors=\"ignore\")[-4000:] if p.exists() else \"(no stderr file)\")\n",
        "except Exception as e:\n",
        "    print(\"\\n--- MCP TEST FAILED ---\")\n",
        "    print(type(e).__name__ + \":\", e)\n",
        "    p = Path(\"/tmp/mcp_server_stderr.log\")\n",
        "    print(\"\\n--- server stderr tail ---\")\n",
        "    print(p.read_text(errors=\"ignore\")[-4000:] if p.exists() else \"(no stderr file)\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vq5ERShb2AVV",
        "outputId": "e1eeb128-7def-4d65-8921-ae794c2fab71"
      },
      "id": "vq5ERShb2AVV",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TOOLS: ['search_locations', 'get_current_weather', 'umbrella_advice']\n",
            "\n",
            "LOCATIONS:\n",
            "{\n",
            "  \"result\": {\n",
            "    \"query\": \"Toronto\",\n",
            "    \"results\": [\n",
            "      {\n",
            "        \"name\": \"Toronto\",\n",
            "        \"country\": \"Canada\",\n",
            "        \"admin1\": \"Ontario\",\n",
            "        \"latitude\": 43.70643,\n",
            "        \"longitude\": -79.39864,\n",
            "        \"timezone\": \"America/Toronto\"\n",
            "      },\n",
            "      {\n",
            "        \"name\": \"Toronto\",\n",
            "        \"country\": \"United States\",\n",
            "        \"admin1\": \"Ohio\",\n",
            "        \"latitude\": 40.46423,\n",
            "        \"longitude\": -80.60091,\n",
            "        \"timezone\": \"America/New_York\"\n",
            "      },\n",
            "      {\n",
            "        \"name\": \"Toronto\",\n",
            "        \"country\": \"United States\",\n",
            "        \"admin1\": \"Kansas\",\n",
            "        \"latitude\": 37.79893,\n",
            "        \"longitude\": -95.94916,\n",
            "        \"timezone\": \"America/Chicago\"\n",
            "      }\n",
            "    ]\n",
            "  }\n",
            "}\n",
            "\n",
            "CURRENT WEATHER:\n",
            "{\n",
            "  \"result\": {\n",
            "    \"timezone\": \"America/Toronto\",\n",
            "    \"latitude\": 43.70643,\n",
            "    \"longitude\": -79.39864,\n",
            "    \"current\": {\n",
            "      \"time\": \"2026-02-24T22:30\",\n",
            "      \"temperature_2m\": -4.8,\n",
            "      \"wind_speed_10m\": 10.1,\n",
            "      \"wind_direction_10m\": 153,\n",
            "      \"weather_code\": 3\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n",
            "UMBRELLA ADVICE:\n",
            "{\n",
            "  \"result\": {\n",
            "    \"city\": \"Toronto\",\n",
            "    \"location\": {\n",
            "      \"name\": \"Toronto\",\n",
            "      \"country\": \"Canada\",\n",
            "      \"admin1\": \"Ontario\",\n",
            "      \"latitude\": 43.70643,\n",
            "      \"longitude\": -79.39864,\n",
            "      \"timezone\": \"America/Toronto\"\n",
            "    },\n",
            "    \"peak_probability\": 83,\n",
            "    \"peak_time\": \"2026-02-25T00:00\",\n",
            "    \"advice\": \"Bring an umbrella. Peak precip probability ~83% around 2026-02-25T00:00.\"\n",
            "  }\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8bf6ad64",
      "metadata": {
        "id": "8bf6ad64"
      },
      "source": [
        "## 1) Write the MCP server (stdio)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f532a297",
      "metadata": {
        "id": "f532a297"
      },
      "source": [
        "## 2) Quick test: call the MCP tools from a tiny stdio client"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6980dd11",
      "metadata": {
        "id": "6980dd11"
      },
      "source": [
        "## 3) (Optional) What to teach in a 1‑day intro\n",
        "\n",
        "**Key concepts to emphasize:**\n",
        "- What MCP is: *a standard way to expose tools/resources/prompts to LLM clients*\n",
        "- Why stdio: simplest transport (works anywhere, easy to demo)\n",
        "- Tools: typed functions (inputs → structured outputs)\n",
        "- “Wrapper value”: validation, safety, normalized outputs, aggregation logic\n",
        "\n",
        "**Suggested 60–90 min lab:**\n",
        "1. Add a new tool: `get_daily_forecast(latitude, longitude, days=3)`\n",
        "2. Make outputs more “LLM friendly”: add `summary` strings\n",
        "3. Add simple input validation (lat/lon ranges, empty query)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}